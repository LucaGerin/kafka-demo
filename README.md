# ğŸ§© Kafka Java Demo â€“ Cluster Kafka con Docker e Java 17 (Temurin)

Questo progetto dimostra come utilizzare **Apache Kafka** con **Java 17 (Eclipse Temurin)** e un **cluster Kafka a 3 broker** eseguito tramite **Docker Compose**. Include `producer` e un `consumer` in Java.

---

## ğŸ“¦ Componenti utilizzati

| Componente        | Versione / Info               |
|-------------------|-------------------------------|
| Java              | 17 (Eclipse Temurin)          |
| Kafka Client      | 3.7.1                          |
| Docker Compose    | v3.8                          |
| Kafka (Broker)    | Confluent Kafka 7.6.0         |
| Zookeeper         | Confluent Zookeeper 7.6.0     |
| SLF4J             | 2.0.9                          |
| Build System      | Maven                         |

---

## ğŸ–¥ï¸ Prerequisiti

Assicurati di avere installati i seguenti strumenti sul tuo computer:


| Strumento         | Versione consigliata | Descrizione                                  |
|-------------------|----------------------|----------------------------------------------|
| [Java JDK](https://adoptium.net/) | 17 (Temurin)         | Linguaggio e runtime Java                    |
| [Apache Maven](https://maven.apache.org/) | 3.8+                | Build system per compilare il progetto       |
| [Docker](https://www.docker.com/products/docker-desktop/) | Ultima stabile     | Container engine per eseguire Kafka e Zookeeper |
| [Docker Compose](https://docs.docker.com/compose/) | v2 o superiore     | Orchestrazione dei container                 |

#### ğŸ“ Repository locale

Clona o scarica il progetto in una cartella sul tuo computer:

```bash
git clone https://github.com/...
```

---

#### âœ… Verifica che tutto sia installato

Esegui questi comandi per verificare lâ€™ambiente:

```bash
java -version
mvn -v
docker --version
docker compose version
```

Tutti dovrebbero restituire informazioni valide senza errori.


## ğŸ“ Struttura del progetto

```text
kafka-demo/
â”œâ”€â”€ docker-compose.yaml         # Cluster Kafka (3 broker + Zookeeper)
â”œâ”€â”€ pom.xml                     # Dipendenze Maven
â”œâ”€â”€ README.md                   # Questo file
â””â”€â”€ src/
    â””â”€â”€ main/java/kafka/
        â”œâ”€â”€ ...
```



---

## ğŸš€ Gestione dei container che realizzano il cluster Kafka

### â–¶ï¸ Avviare i container con Docker Compose

Esegui il seguente comando dalla cartella del progetto:

```bash
docker compose up -d
```
Questo avvierÃ :

- ğŸ˜ **1 container Zookeeper**
- ğŸ“¦ **3 container Kafka broker**, sulle seguenti porte:
    - `kafka1`: `localhost:9092`
    - `kafka2`: `localhost:9093`
    - `kafka3`: `localhost:9094`

Per verificare che i container siano attivi:
```bash
docker ps
```

## ğŸ§¹ Pulizia dei container Docker

Quando non ti servono piÃ¹ i container Kafka e Zookeeper, puoi fermarli o eliminarli completamente.

### ğŸ›‘ Fermare i container (senza eliminarli)

Questo comando **spegne i container**, ma non li rimuove:

```bash
docker compose stop
```

### â–¶ï¸ Riavviare i container fermati

Per **riavviare i container fermati** (senza ricrearli):

```bash
docker compose start
```

Questo Ã¨ utile se hai giÃ  avviato il cluster almeno una volta con `up` e vuoi solo riaccenderlo.


---

### âŒ Eliminare i container

Per **rimuovere i container**, mantenendo perÃ² le immagini e i volumi:

```bash
docker compose down
```

---

### ğŸ’£ Eliminare anche i volumi (opzionale)

Se vuoi **rimuovere i container e anche i dati** (inclusi log, topic, offset, ecc.):

```bash
docker compose down --volumes
```

âš ï¸ Attenzione: questo comando cancella **tutti i dati** salvati da Kafka (topic, messaggi, ecc.).

---


## ğŸ§ª Comandi utili da terminale

Puoi usare questi comandi tramite Docker per gestire i topic, testare i messaggi e monitorare il cluster.

> **Tutti i comandi vanno eseguiti dal terminale del tuo sistema operativo**, nella stessa cartella dove si trova il file `docker-compose.yaml`.
> Assicurati che i container Kafka siano in esecuzione (`docker compose up -d`).

---

### ğŸ”§ Creare un topic

```bash
docker exec kafka1 kafka-topics --create --topic test-topic --partitions 3 --replication-factor 3 --bootstrap-server localhost:9092
```

â¡ï¸ Crea un topic chiamato `test-topic` con 3 partizioni e 3 repliche, connesso al broker `kafka1`.

---

### ğŸ“‹ Elencare tutti i topic

```bash
docker exec kafka1 kafka-topics --list --bootstrap-server localhost:9092
```

â¡ï¸ Mostra l'elenco dei topic nel cluster.

---

### ğŸ” Descrivere un topic

```bash
docker exec kafka1 kafka-topics --describe --topic test-topic --bootstrap-server localhost:9092
```

â¡ï¸ Mostra informazioni sul topic `test-topic`, incluse partizioni e repliche.

---

### ğŸ“¤ Inviare un messaggio manuale (console producer)

```bash
docker exec -it kafka1 kafka-console-producer --topic test-topic --bootstrap-server localhost:9092
```

â¡ï¸ Apre un prompt interattivo dove puoi scrivere messaggi che verranno inviati al topic.

---

### ğŸ“¥ Leggere i messaggi da un topic (console consumer)

```bash
docker exec -it kafka1 kafka-console-consumer --topic test-topic --from-beginning --bootstrap-server localhost:9092
```

â¡ï¸ Legge tutti i messaggi presenti nel topic `test-topic`, anche quelli giÃ  inviati.

---

### ğŸš® Eliminare un topic

```bash
docker exec kafka1 kafka-topics --delete --topic test-topic --bootstrap-server localhost:9092
```

â¡ï¸ Elimina il topic `test-topic` dal cluster.

---

ğŸ“ **Nota:** puoi usare `kafka2` o `kafka3` al posto di `kafka1` nei comandi, dato che tutti i broker appartengono allo stesso cluster.